{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check time format and do imputation accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "lines = open(\"Hoppe_without.csv\",'r').read().split('\\n')\n",
    "del lines[-1]\n",
    "del lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning: find labor time, delivery date and BP information at certain time period for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data processing to find specific patient information under certain ##\n",
    "## conditions from specific dataset ##\n",
    "\n",
    "MRN = []\n",
    "delivery_time = []\n",
    "bp_high = []\n",
    "bp_low = []\n",
    "labor_time = []\n",
    "\n",
    "for line in lines:\n",
    "    Lis = line.split(\",\")\n",
    "    n = len(Lis)\n",
    "    Lis[1]=pd.to_datetime(Lis[1]).strftime('%y-%m-%d %H:%M')\n",
    "    for i in range(int((n-2)/3)):\n",
    "        Lis[4+i*3]=pd.to_datetime(Lis[4+i*3]).strftime('%y-%m-%d %H:%M')\n",
    "        if Lis[1]> Lis[4+i*3]:\n",
    "            MRN.append(Lis[0])\n",
    "            delivery_time.append(Lis[1])\n",
    "            bp_high.append(Lis[2+i*3])\n",
    "            bp_low.append(Lis[3+i*3])\n",
    "            labor_time.append(Lis[4+i*3])\n",
    "        \n",
    "df = pd.DataFrame({'MRN': MRN,\n",
    "                   'delivery_time': delivery_time,\n",
    "                   'bp_high': bp_high,\n",
    "                   'bp_low': bp_low,\n",
    "                   'labor_time':labor_time\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify time format ##\n",
    "\n",
    "a=df['delivery_time']\n",
    "b=a.values.tolist()\n",
    "delivery_date=[]\n",
    "for x in b:\n",
    "    #delivery_date.append(pd.to_datetime(x).strftime('%y-%m-%d'))\n",
    "    delivery_date.append(pd.to_datetime(x, yearfirst = True).strftime('%y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_date']=delivery_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_date = df.drop(['delivery_time'], axis=1)\n",
    "df_date = df_date.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date['bp_high'] = [int(i) for i in df_date['bp_high']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find highest BP values ##\n",
    "\n",
    "df_date.sort_values(['MRN','delivery_date','bp_high'],ascending=[1,1,0],inplace=True)\n",
    "grouped = df_date.groupby(['MRN','delivery_date']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1 = df_date.groupby(['MRN','delivery_date']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.columns = [\"mother's_mrn\", 'bp_high', 'bp_low', 'labor_time', 'date of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1.columns = [\"mother's_mrn\", 'bp_high', 'bp_low', 'labor_time', 'date of_birth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge feature information from other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = pd.ExcelFile('Hoppe_HTN_Data_9.2020.xlsx')\n",
    "df1 = pd.read_excel(HP, 'Old Data')\n",
    "df1['date of_birth']=df1['date of_birth'].apply(lambda x: x.strftime('%y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(grouped['date of_birth'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date of_birth'] = pd.to_datetime(df1['date of_birth'], yearfirst = True)\n",
    "grouped['date of_birth'] = pd.to_datetime(grouped['date of_birth'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1['date of_birth'] = pd.to_datetime(grouped1['date of_birth'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge patient information on MRN and date of birth ##\n",
    "\n",
    "grouped1[\"mother's_mrn\"] = grouped1[\"mother's_mrn\"].astype(str).astype(int)\n",
    "olddff = pd.merge(df1, grouped1, on=[\"mother's_mrn\",'date of_birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data processing to find specific patient information under certain (after delivery 0-24h) ##\n",
    "## conditions from specific dataset ##\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "MRN = []\n",
    "delivery_time = []\n",
    "bp_high24 = []\n",
    "bp_low24 = []\n",
    "labor_time = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    Lis = line.split(\",\")\n",
    "    n = len(Lis)\n",
    "    #list[1]=pd.to_datetime(list[1]).strftime('%y-%m-%d %H:%M')\n",
    "    Lis[1]=pd.to_datetime(Lis[1])\n",
    "    for i in range(int((n-2)/3)):\n",
    "        #list[4+i*3]=pd.to_datetime(list[4+i*3]).strftime('%y-%m-%d %H:%M')\n",
    "        Lis[4+i*3]=pd.to_datetime(Lis[4+i*3])\n",
    "        diff = pd.Timedelta(Lis[4+i*3] - Lis[1], unit = 'hours').total_seconds()/3600\n",
    "        if  0<diff<24:\n",
    "            #print(list[4+i*3].strftime('%y-%m-%d %H:%M')+','+list[1].strftime('%y-%m-%d %H:%M'))\n",
    "            MRN.append(Lis[0])\n",
    "            delivery_time.append(Lis[1])\n",
    "            bp_high24.append(Lis[2+i*3])\n",
    "            bp_low24.append(Lis[3+i*3])\n",
    "            labor_time.append(Lis[4+i*3])\n",
    "        \n",
    "df_1d = pd.DataFrame({'MRN': MRN,\n",
    "                   'delivery_time': delivery_time,\n",
    "                   'bp_high24': bp_high24,\n",
    "                   'bp_low24': bp_low24,\n",
    "                   'labor_time':labor_time\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_1d['delivery_time']\n",
    "b=a.values.tolist()\n",
    "delivery_date=[]\n",
    "for x in b:\n",
    "    #delivery_date.append(pd.to_datetime(x).strftime('%y-%m-%d'))\n",
    "    delivery_date.append(pd.to_datetime(x, yearfirst = True).strftime('%y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1d['delivery_date']=delivery_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df_1d.drop(['delivery_time'], axis=1)\n",
    "df_date = df_date.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date['bp_high24'] = [int(i) for i in df_date['bp_high24']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.sort_values(['MRN','delivery_date','bp_high24'],ascending=[1,1,0],inplace=True)\n",
    "grouped = df_date.groupby(['MRN','delivery_date']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1 = df_date.groupby(['MRN','delivery_date']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.columns = [\"mother's_mrn\", 'bp_high24', 'bp_low24', 'labor_time', 'date of_birth']\n",
    "grouped1.columns = [\"mother's_mrn\", 'bp_high24', 'bp_low24', 'labor_time', 'date of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['date of_birth'] = pd.to_datetime(grouped['date of_birth'], yearfirst = True)\n",
    "grouped1['date of_birth'] = pd.to_datetime(grouped1['date of_birth'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1[\"mother's_mrn\"] = grouped1[\"mother's_mrn\"].astype(str).astype(int)\n",
    "olddfff = pd.merge(olddff, grouped1, on=[\"mother's_mrn\",'date of_birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data processing to find specific patient information under certain (after delivery 24-48h) ##\n",
    "## conditions from specific dataset ##\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "MRN = []\n",
    "delivery_time = []\n",
    "bp_high48 = []\n",
    "bp_low48 = []\n",
    "labor_time = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    Lis = line.split(\",\")\n",
    "    n = len(Lis)\n",
    "    #list[1]=pd.to_datetime(list[1]).strftime('%y-%m-%d %H:%M')\n",
    "    Lis[1]=pd.to_datetime(Lis[1])\n",
    "    for i in range(int((n-2)/3)):\n",
    "        #list[4+i*3]=pd.to_datetime(list[4+i*3]).strftime('%y-%m-%d %H:%M')\n",
    "        Lis[4+i*3]=pd.to_datetime(Lis[4+i*3])\n",
    "        diff = pd.Timedelta(Lis[4+i*3] - Lis[1], unit = 'hours').total_seconds()/3600\n",
    "        if  24<diff<48:\n",
    "            print(Lis[4+i*3].strftime('%y-%m-%d %H:%M')+','+Lis[1].strftime('%y-%m-%d %H:%M'))\n",
    "            MRN.append(Lis[0])\n",
    "            delivery_time.append(Lis[1])\n",
    "            bp_high48.append(Lis[2+i*3])\n",
    "            bp_low48.append(Lis[3+i*3])\n",
    "            labor_time.append(Lis[4+i*3])\n",
    "        \n",
    "df_2d = pd.DataFrame({'MRN': MRN,\n",
    "                   'delivery_time': delivery_time,\n",
    "                   'bp_high48': bp_high48,\n",
    "                   'bp_low48': bp_low48,\n",
    "                   'labor_time':labor_time\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_2d['delivery_time']\n",
    "b=a.values.tolist()\n",
    "delivery_date=[]\n",
    "for x in b:\n",
    "    #delivery_date.append(pd.to_datetime(x).strftime('%y-%m-%d'))\n",
    "    delivery_date.append(pd.to_datetime(x, yearfirst = True).strftime('%y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2d['delivery_date']=delivery_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df_2d.drop(['delivery_time'], axis=1)\n",
    "df_date = df_date.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date['bp_high48'] = [int(i) for i in df_date['bp_high48']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.sort_values(['MRN','delivery_date','bp_high48'],ascending=[1,1,0],inplace=True)\n",
    "grouped = df_date.groupby(['MRN','delivery_date']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1 = df_date.groupby(['MRN','delivery_date']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.columns = [\"mother's_mrn\", 'bp_high48', 'bp_low48', 'labor_time', 'date of_birth']\n",
    "grouped1.columns = [\"mother's_mrn\", 'bp_high48', 'bp_low48', 'labor_time', 'date of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['date of_birth'] = pd.to_datetime(grouped['date of_birth'], yearfirst = True)\n",
    "grouped1['date of_birth'] = pd.to_datetime(grouped1['date of_birth'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped1[\"mother's_mrn\"] = grouped1[\"mother's_mrn\"].astype(str).astype(int)\n",
    "olddffff = pd.merge(olddfff, grouped1, on=[\"mother's_mrn\",'date of_birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic infomation collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddemo = olddffff[[\"mother's_mrn\",'maternal_age','bp_high24','bp_low24','bp_high48','bp_low48','bp_high','bp_low',\"m9's bmi_prepregnancy\",'nullipara/_multipara',\"gestational_age (ob_clinician's_final estimate-_calculated)\",'primary_race','final_route and_method of_delivery','hispanic_origin','READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2']]\n",
    "olddemo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#throw NaN in each column.\n",
    "olddemo = olddemo.replace('.', np.nan)\n",
    "olddemo.dropna(subset=['bp_high24','bp_low24','bp_high48','bp_low48', 'bp_high', 'bp_low', \"m9's bmi_prepregnancy\"], how='any', axis=0, inplace = True)\n",
    "print(olddemo.shape)\n",
    "olddemo.head()\n",
    "olddemo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddemo['READMIT_ ADM_DATE_TIME_1'].fillna(0,inplace=True)\n",
    "olddemo['READMIT_ ADM_DATE_TIME_1']=olddemo['READMIT_ ADM_DATE_TIME_1'].apply(lambda x: 1 if x!=0 else 0)\n",
    "olddemo['READMIT_ ADM_DATE_TIME_2'].fillna(0,inplace=True)\n",
    "olddemo['READMIT_ ADM_DATE_TIME_2']=olddemo['READMIT_ ADM_DATE_TIME_2'].apply(lambda x: 1 if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmit = np.logical_or(olddemo['READMIT_ ADM_DATE_TIME_1'] > 0, olddemo['READMIT_ ADM_DATE_TIME_2'] > 0)\n",
    "olddemo['Readmit'] = readmit\n",
    "# change True False to 1 0\n",
    "olddemo['Readmit'] = olddemo['Readmit']*1\n",
    "olddemo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldbpdiag['bp_low'] = oldbpdiag['bp_low'].astype(int)\n",
    "oldbpdiag['bp_low24'] = oldbpdiag['bp_low24'].astype(int)\n",
    "oldbpdiag['bp_low48'] = oldbpdiag['bp_low48'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldps = oldbpdiag[\"mother's_mrn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label patients under certain criteria ##\n",
    "\n",
    "Index_label1 = oldbpdiag[(oldbpdiag['bp_low']>90)|(oldbpdiag['bp_high']>140)].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index_label2 = oldbpdiag[(oldbpdiag['bp_low24']>90)|(oldbpdiag['bp_high24']>140)].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index_label3 = oldbpdiag[(oldbpdiag['bp_low48']>90)|(oldbpdiag['bp_high48']>140)].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "qulify1_set = set.intersection(set(Index_label1), set(Index_label2))\n",
    "qulify2_set = set.intersection(set(Index_label1), set(Index_label3))\n",
    "qulify3_set = set.intersection(set(Index_label2), set(Index_label3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldqulify = qulify1_set.union(qulify2_set, qulify3_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index_label4 = oldbpdiag[(oldbpdiag['protein_24_hour_ur_fst_tm'].isnull())].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index_label5 = oldbpdiag[(oldbpdiag['protein_24_hour_ur_fst_tm'].notnull())].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesqualify = set.intersection(set(oldqulify), set(Index_label4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "preeclamquali = set.intersection(set(oldqulify), set(Index_label5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddffff_key = olddffff[['READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','bp_high24','bp_low24','bp_high48','bp_low48',\"m9's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low']]\n",
    "summary_key=olddffff_key.isnull().sum()\n",
    "summary_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old data without med information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#throw NaN in each column.\n",
    "olddffff_key = olddffff_key.replace('.', np.nan)\n",
    "olddffff_key.dropna(subset=['bp_high24','bp_low24','bp_high48','bp_low48',\"m9's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low'], how='any', axis=0, inplace = True)\n",
    "print(olddffff_key.shape)\n",
    "olddffff_key.head()\n",
    "olddffff_key.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddffff_key['READMIT_ ADM_DATE_TIME_1'].fillna(0,inplace=True)\n",
    "olddffff_key['READMIT_ ADM_DATE_TIME_1']=olddffff_key['READMIT_ ADM_DATE_TIME_1'].apply(lambda x: 1 if x!=0 else 0)\n",
    "olddffff_key['READMIT_ ADM_DATE_TIME_2'].fillna(0,inplace=True)\n",
    "olddffff_key['READMIT_ ADM_DATE_TIME_2']=olddffff_key['READMIT_ ADM_DATE_TIME_2'].apply(lambda x: 1 if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmit = np.logical_or(olddffff_key['READMIT_ ADM_DATE_TIME_1'] > 0, olddffff_key['READMIT_ ADM_DATE_TIME_2'] > 0)\n",
    "olddffff_key['Readmit'] = readmit\n",
    "# change True False to 1 0\n",
    "olddffff_key['Readmit'] = olddffff_key['Readmit']*1\n",
    "olddffff_key.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medication data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Med data\n",
    "MD = pd.ExcelFile('Old Data - Only MRN and Medication.xlsx')\n",
    "Medinfo = pd.read_excel(MD, 'Sheet1')\n",
    "print(Medinfo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mednodup = Medinfo.drop_duplicates()\n",
    "Mednodup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Medlist = Mednodup.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data processing to find specific medication information under certain ##\n",
    "## conditions from specific dataset ##\n",
    "\n",
    "MRN = []\n",
    "med_time = []\n",
    "med_name = []\n",
    "med_dose = []\n",
    "dose_unit = []\n",
    "route = []\n",
    "\n",
    "n=131\n",
    "\n",
    "for j in range(len(Mednodup)):\n",
    "    for i in range(int((n-1)/5)):\n",
    "        MRN.append(Mednodup.iloc[j,0])\n",
    "        med_time.append(Mednodup.iloc[j,5*i+1])\n",
    "        med_name.append(Mednodup.iloc[j,5*i+2])\n",
    "        med_dose.append(Mednodup.iloc[j,5*i+3])\n",
    "        dose_unit.append(Mednodup.iloc[j,5*i+4])\n",
    "        route.append(Mednodup.iloc[j,5*i+5])\n",
    "        \n",
    "df_minfo = pd.DataFrame({'MRN': MRN,\n",
    "                   'med_time': med_time,\n",
    "                   'med_name': med_name,\n",
    "                   'med_dose': med_dose,\n",
    "                   'dose_unit': dose_unit,\n",
    "                   'route':route\n",
    "                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing medication information from text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minfo = df_minfo.replace('15-30', 30)\n",
    "df_minfo = df_minfo.replace('400-800', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minfo.loc[df_minfo['med_dose'].apply(lambda x: isinstance(x,datetime.date)),'med_dose'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_minfo.loc[df_minfo['MRN'] == 409754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = (\n",
    "    df_minfo.groupby('MRN')\n",
    "    .apply(lambda x: (x['med_name'].eq(1)).any())\n",
    "    .to_frame('If Ibuprofen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minfo[\"ifnacute\"] = ((df_minfo[\"med_name\"] == 2)&(df_minfo[\"med_dose\"].fillna(-1)>=10)&(df_minfo[\"med_dose\"].fillna(-1)<=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_minfo[(df_minfo[\"med_name\"] == 2)&(df_minfo[\"med_dose\"].fillna(-1)>=10)&(df_minfo[\"med_dose\"].fillna(-1)<=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minfo[\"ifnsustain\"] = ((df_minfo[\"med_name\"] == 2)&(df_minfo[\"med_dose\"].fillna(-1)>=30)&(df_minfo[\"med_dose\"].fillna(-1)<=90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_1 = (\n",
    "    df_minfo.groupby('MRN')\n",
    "    .apply(lambda x: (x['ifnacute'].eq(True)).any())\n",
    "    .to_frame('If nifedipine acute'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M2_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_2 = (\n",
    "    df_minfo.groupby('MRN')\n",
    "    .apply(lambda x: (x['ifnsustain'].eq(True)).any())\n",
    "    .to_frame('If nifedipine sustain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minfo[(df_minfo[\"med_name\"] == 2)&(df_minfo[\"med_dose\"].fillna(-1)>=30)&(df_minfo[\"med_dose\"].fillna(-1)<=90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_1 = (\n",
    "    df_minfo.groupby('MRN')\n",
    "    .apply(lambda x: (x['med_name'].eq(3) & x['route'].eq('IV')).any())\n",
    "    .to_frame('If Labetalol given IV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_2 = (\n",
    "    df_minfo.groupby('MRN')\n",
    "    .apply(lambda x: (x['med_name'].eq(3) & x['route'].eq('PO')).any())\n",
    "    .to_frame('If Labetalol given PO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "M6 = (\n",
    "    df_minfo.groupby('MRN')\n",
    "    .apply(lambda x: (x['med_name'].eq(6)).any())\n",
    "    .to_frame('If hydralazine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Mdata = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(M1,M2_1,on='MRN'),M2_2,on='MRN'),M3_1,on='MRN'),M3_2,on='MRN'),M6,on='MRN')\n",
    "Mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdata1 = Mdata.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdata1.columns = [\"mother's_mrn\", 'If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine']\n",
    "olddfwithmed = pd.merge(olddffff, Mdata1, on=[\"mother's_mrn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old data with medication information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddfwithmed_key = olddfwithmed[['READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','bp_high24','bp_low24','bp_high48','bp_low48',\"m9's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low','If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine']]\n",
    "summary_key=olddfwithmed_key.isnull().sum()\n",
    "summary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddfwithmed_key = olddfwithmed_key.replace('.', np.nan)\n",
    "olddfwithmed_key.dropna(subset=['bp_high24','bp_low24','bp_high48','bp_low48',\"m9's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low','If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine'], how='any', axis=0, inplace = True)\n",
    "print(olddfwithmed_key.shape)\n",
    "olddfwithmed_key.head()\n",
    "olddfwithmed_key.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olddfwithmed_key['READMIT_ ADM_DATE_TIME_1'].fillna(0,inplace=True)\n",
    "olddfwithmed_key['READMIT_ ADM_DATE_TIME_1']=olddfwithmed_key['READMIT_ ADM_DATE_TIME_1'].apply(lambda x: 1 if x!=0 else 0)\n",
    "olddfwithmed_key['READMIT_ ADM_DATE_TIME_2'].fillna(0,inplace=True)\n",
    "olddfwithmed_key['READMIT_ ADM_DATE_TIME_2']=olddfwithmed_key['READMIT_ ADM_DATE_TIME_2'].apply(lambda x: 1 if x!=0 else 0)\n",
    "# change True False to 1 0\n",
    "olddfwithmed_key['If Ibuprofen'] = olddfwithmed_key['If Ibuprofen']*1\n",
    "olddfwithmed_key['If nifedipine acute'] = olddfwithmed_key['If nifedipine acute']*1\n",
    "olddfwithmed_key['If nifedipine sustain'] = olddfwithmed_key['If nifedipine sustain']*1\n",
    "olddfwithmed_key['If Labetalol given IV'] = olddfwithmed_key['If Labetalol given IV']*1\n",
    "olddfwithmed_key['If Labetalol given PO'] = olddfwithmed_key['If Labetalol given PO']*1\n",
    "olddfwithmed_key['If hydralazine'] = olddfwithmed_key['If hydralazine']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmit = np.logical_or(olddfwithmed_key['READMIT_ ADM_DATE_TIME_1'] > 0, olddfwithmed_key['READMIT_ ADM_DATE_TIME_2'] > 0)\n",
    "olddfwithmed_key['Readmit'] = readmit\n",
    "# change True False to 1 0\n",
    "olddfwithmed_key['Readmit'] = olddfwithmed_key['Readmit']*1\n",
    "olddfwithmed_key.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddfwithmed_key.loc[olddfwithmed_key['Readmit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddfwithmed_key.to_csv('olddata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same thing for the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = pd.ExcelFile('Hoppe_HTN_Data_9.2020.xlsx')\n",
    "dfnew = pd.read_excel(HP, 'New Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_laborbp = dfnew[[\"mother's_mrn\",'sysbp_labor1','diabp_labor1','sysbp_labor2','diabp_labor2','sysbp_labor3','diabp_labor3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRN = []\n",
    "bp_high = []\n",
    "bp_low = []\n",
    "\n",
    "n=7\n",
    "\n",
    "for j in range(len(dfnew_laborbp)):\n",
    "    for i in range(int((n-1)/2)):\n",
    "        MRN.append(dfnew_laborbp.iloc[j,0])\n",
    "        bp_high.append(dfnew_laborbp.iloc[j,2*i+1])\n",
    "        bp_low.append(dfnew_laborbp.iloc[j,2*i+2])\n",
    "        \n",
    "dfnew_bpns = pd.DataFrame({'MRN': MRN,\n",
    "                   'bp_high': bp_high,\n",
    "                   'bp_low': bp_low\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_bpns = dfnew_bpns.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_bpns = dfnew_bpns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_bpns['bp_high'] = [float(i) for i in dfnew_bpns['bp_high']] \n",
    "dfnew_bpns.sort_values(['MRN','bp_high'],ascending=[1,0],inplace=True)\n",
    "grouped_1 = dfnew_bpns.groupby(['MRN']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_1.columns = [\"mother's_mrn\", 'bp_high', 'bp_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdfbp = pd.merge(grouped_1,dfnew,on=\"mother's_mrn\")\n",
    "newdfbp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdfbp = newdfbp.drop_duplicates(subset=[\"mother's_mrn\", 'bp_high', 'bp_low'], keep='last')\n",
    "newdfbp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New data Med info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_med = pd.read_excel('January_2020_-_15_through_18_data_combinedv4.xlsx', 'Meds 15-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_med = dfnew_med.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_med['If Ibuprofen'] = dfnew_med['Medication Name'].str.contains(\"ibuprofen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_med['If nifedipine sustain'] = (dfnew_med['Medication Name'].str.contains(\"NIFEdipine\")) & (dfnew_med['Medication Name'].str.contains(\"tablet\"))\n",
    "dfnew_med['If nifedipine acute'] = (dfnew_med['Medication Name'].str.contains(\"NIFEdipine\")) & (dfnew_med['Medication Name'].str.contains(\"capsule\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_med['If Labetalol given IV'] = (dfnew_med['Medication Name'].str.contains(\"labetalol\")) & (dfnew_med['Medication Name'].str.contains(\"injection|syringe|infusion\"))\n",
    "dfnew_med['If Labetalol given PO'] = (dfnew_med['Medication Name'].str.contains(\"labetalol\")) & (dfnew_med['Medication Name'].str.contains(\"tablet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_med['If hydralazine'] = dfnew_med['Medication Name'].str.contains(\"hydrALAZINE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = dfnew_med.columns[dfnew_med.dtypes == 'bool']\n",
    "dfnew_med[bool_cols] = dfnew_med[bool_cols].replace({True: 'Yes', False: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_1 = (\n",
    "    dfnew_med.groupby('id')\n",
    "    .apply(lambda x: x['If Ibuprofen'].eq('Yes').any())\n",
    "    .to_frame('If Ibuprofen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_21 = (\n",
    "    dfnew_med.groupby('id')\n",
    "    .apply(lambda x: x['If nifedipine acute'].eq('Yes').any())\n",
    "    .to_frame('If nifedipine acute'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_22 = (\n",
    "    dfnew_med.groupby('id')\n",
    "    .apply(lambda x: x['If nifedipine sustain'].eq('Yes').any())\n",
    "    .to_frame('If nifedipine sustain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_31 = (\n",
    "    dfnew_med.groupby('id')\n",
    "    .apply(lambda x: x['If Labetalol given IV'].eq('Yes').any())\n",
    "    .to_frame('If Labetalol given IV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_32 = (\n",
    "    dfnew_med.groupby('id')\n",
    "    .apply(lambda x: x['If Labetalol given PO'].eq('Yes').any())\n",
    "    .to_frame('If Labetalol given PO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_6 = (\n",
    "    dfnew_med.groupby('id')\n",
    "    .apply(lambda x: x['If hydralazine'].eq('Yes').any())\n",
    "    .to_frame('If hydralazine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMdata = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(NM_1,NM_21,on='id'),NM_22,on='id'),NM_31,on='id'),NM_32,on='id'),NM_6,on='id')\n",
    "NMdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMdata1 = NMdata.reset_index()\n",
    "NMdata1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMdata1.columns = [\"mother's_mrn\", 'If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine']\n",
    "newdfwithmed = newdfbp.merge(NMdata1, on=\"mother's_mrn\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfwithmed[['If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine']] = newdfwithmed[['If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine']].fillna(False).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics for new data and combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdemo = newdfwithmed[[\"mother's_mrn\",'maternal_age','sysbp_24deliv1','diabp_24deliv1','sysbp_24_48deliv1','diabp_24_48deliv1','bp_high','bp_low',\"mother's bmi_prepregnancy\",'nullipara/_multipara',\"gestational_age (ob_clinician's_final estimate-_calculated)\",'primary_race','hispanic_origin','final_route and_method of_delivery','READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdemo.dropna(subset=['sysbp_24deliv1','diabp_24deliv1','sysbp_24_48deliv1','diabp_24_48deliv1',\"mother's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low'], how='any', axis=0, inplace = True)\n",
    "print(newdemo.shape)\n",
    "newdemo.head()\n",
    "newdemo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdemo['READMIT_ ADM_DATE_TIME_1'].fillna(0,inplace=True)\n",
    "newdemo['READMIT_ ADM_DATE_TIME_1']=newdemo['READMIT_ ADM_DATE_TIME_1'].apply(lambda x: 1 if x!=0 else 0)\n",
    "newdemo['READMIT_ ADM_DATE_TIME_2'].fillna(0,inplace=True)\n",
    "newdemo['READMIT_ ADM_DATE_TIME_2']=newdemo['READMIT_ ADM_DATE_TIME_2'].apply(lambda x: 1 if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newreadmit = np.logical_or(newdemo['READMIT_ ADM_DATE_TIME_1'] > 0, newdemo['READMIT_ ADM_DATE_TIME_2'] > 0)\n",
    "newdemo['Readmit'] = newreadmit\n",
    "# change True False to 1 0\n",
    "newdemo['Readmit'] = newdemo['Readmit']*1\n",
    "newdemo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdemo = newdemo[[\"mother's_mrn\", \"maternal_age\", \"sysbp_24deliv1\", \"diabp_24deliv1\", \"sysbp_24_48deliv1\", \"diabp_24_48deliv1\", \"bp_high\", \"bp_low\", \"mother's bmi_prepregnancy\", \"nullipara/_multipara\", \"gestational_age (ob_clinician's_final estimate-_calculated)\", \"primary_race\", \"final_route and_method of_delivery\", \"hispanic_origin\", \"READMIT_ ADM_DATE_TIME_1\", \"READMIT_ ADM_DATE_TIME_2\", \"Readmit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdemo=newdemo.rename(columns={\"sysbp_24deliv1\": \"bp_high24\", \"diabp_24deliv1\": \"bp_low24\", \"sysbp_24_48deliv1\": \"bp_high48\", \"diabp_24_48deliv1\": \"bp_low48\", \"mother's bmi_prepregnancy\": \"m9's bmi_prepregnancy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo=olddemo.append(newdemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo['nullipara/_multipara']=alldemo['nullipara/_multipara'].fillna(2)\n",
    "alldemo['primary_race']=alldemo['primary_race'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])['maternal_age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])['maternal_age'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])['nullipara/_multipara'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])[\"gestational_age (ob_clinician's_final estimate-_calculated)\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])[\"gestational_age (ob_clinician's_final estimate-_calculated)\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])['primary_race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])['hispanic_origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])[\"m9's bmi_prepregnancy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])[\"m9's bmi_prepregnancy\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo.groupby(['Readmit'])['final_route and_method of_delivery'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo['maternal_age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo['maternal_age'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo[\"gestational_age (ob_clinician's_final estimate-_calculated)\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo[\"gestational_age (ob_clinician's_final estimate-_calculated)\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo[\"m9's bmi_prepregnancy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldemo[\"m9's bmi_prepregnancy\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting dataframe for new data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdfwithmed_key = newdfwithmed[['READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','sysbp_24deliv1','diabp_24deliv1','sysbp_24_48deliv1','diabp_24_48deliv1',\"mother's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low','If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine']]\n",
    "summary_key=newdfwithmed_key.isnull().sum()\n",
    "summary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdfwithmed_key.dropna(subset=['sysbp_24deliv1','diabp_24deliv1','sysbp_24_48deliv1','diabp_24_48deliv1',\"mother's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age', 'bp_high', 'bp_low','If Ibuprofen', 'If nifedipine acute', 'If nifedipine sustain', 'If Labetalol given IV', 'If Labetalol given PO', 'If hydralazine'], how='any', axis=0, inplace = True)\n",
    "print(newdfwithmed_key.shape)\n",
    "newdfwithmed_key.head()\n",
    "newdfwithmed_key.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newps = newdfwithmed_key[\"mother's_mrn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfwithmed_key['READMIT_ ADM_DATE_TIME_1'].fillna(0,inplace=True)\n",
    "newdfwithmed_key['READMIT_ ADM_DATE_TIME_1']=newdfwithmed_key['READMIT_ ADM_DATE_TIME_1'].apply(lambda x: 1 if x!=0 else 0)\n",
    "newdfwithmed_key['READMIT_ ADM_DATE_TIME_2'].fillna(0,inplace=True)\n",
    "newdfwithmed_key['READMIT_ ADM_DATE_TIME_2']=newdfwithmed_key['READMIT_ ADM_DATE_TIME_2'].apply(lambda x: 1 if x!=0 else 0)\n",
    "# change True False to 1 0\n",
    "newdfwithmed_key['If Ibuprofen'] = newdfwithmed_key['If Ibuprofen']*1\n",
    "newdfwithmed_key['If nifedipine acute'] = newdfwithmed_key['If nifedipine acute']*1\n",
    "newdfwithmed_key['If nifedipine sustain'] = newdfwithmed_key['If nifedipine sustain']*1\n",
    "newdfwithmed_key['If Labetalol given IV'] = newdfwithmed_key['If Labetalol given IV']*1\n",
    "newdfwithmed_key['If Labetalol given PO'] = newdfwithmed_key['If Labetalol given PO']*1\n",
    "newdfwithmed_key['If hydralazine'] = newdfwithmed_key['If hydralazine']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newreadmit = np.logical_or(newdfwithmed_key['READMIT_ ADM_DATE_TIME_1'] > 0, newdfwithmed_key['READMIT_ ADM_DATE_TIME_2'] > 0)\n",
    "newdfwithmed_key['Readmit'] = newreadmit\n",
    "# change True False to 1 0\n",
    "newdfwithmed_key['Readmit'] = newdfwithmed_key['Readmit']*1\n",
    "newdfwithmed_key.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfwithmed_key.columns = ['READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','bp_high24','bp_low24','bp_high48','bp_low48',\"m9's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age','bp_high','bp_low','If Ibuprofen','If nifedipine acute','If nifedipine sustain','If Labetalol given IV','If Labetalol given PO','If hydralazine','Readmit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfwithmed_key = newdfwithmed_key[['READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','bp_high24','bp_low24','bp_high48','bp_low48',\"m9's bmi_prepregnancy\",\"gestational_age (ob_clinician's_final estimate-_calculated)\",'maternal_age','bp_high','bp_low','If Ibuprofen','If nifedipine acute','If nifedipine sustain','If Labetalol given IV','If Labetalol given PO','If hydralazine','Readmit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfwithmed_key.loc[newdfwithmed_key['Readmit']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineddf = olddfwithmed_key.append(newdfwithmed_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineddf.to_csv('mergeddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "combineddf = pd.read_csv('mergeddata.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combineddf.drop(['Unnamed: 0','READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','Readmit'],axis=1)\n",
    "y = combineddf.Readmit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check feature correlation ##\n",
    "\n",
    "X.rename(columns={\"m9's bmi_prepregnancy\": \"bmi_prepregnancy\", \"gestational_age (ob_clinician's_final estimate-_calculated)\": \"gestational_age\"}, inplace = True)\n",
    "corr = X.corr()\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.savefig(\"all_data_corr.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old and new data sets\n",
    "X_old, y_old = X.iloc[0:21037], y.iloc[0:21037]\n",
    "X_new, y_new = X.iloc[21037:], y.iloc[21037:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_old = X_old.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_new = X_new.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check feature correlation ##\n",
    "\n",
    "X_old.rename(columns={\"m9's bmi_prepregnancy\": \"bmi_prepregnancy\", \"gestational_age (ob_clinician's_final estimate-_calculated)\": \"gestational_age\"}, inplace = True)\n",
    "corr = X_old.corr()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.savefig(\"old_data_corr.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check feature correlation ##\n",
    "\n",
    "X_new.rename(columns={\"m9's bmi_prepregnancy\": \"bmi_prepregnancy\", \"gestational_age (ob_clinician's_final estimate-_calculated)\": \"gestational_age\"}, inplace = True)\n",
    "corr = X_new.corr()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If no BP features? ##\n",
    "X_nobp = combineddf.drop(['Unnamed: 0','bp_high24','bp_low24','bp_high48','bp_low48','bp_high','bp_low','READMIT_ ADM_DATE_TIME_1','READMIT_ ADM_DATE_TIME_2','Readmit'],axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_o = scaler.fit_transform(X_old)\n",
    "scaled_n = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation hyperparameter tuning ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "rf_o_result_dfs = []\n",
    "for balance in balances:\n",
    "    print('I am bal')\n",
    "    lis = []\n",
    "    for i in m_dep:\n",
    "        for j in n_est:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_o, y_old):\n",
    "                X_train_fold, X_test_fold = scaled_o[train_index], scaled_o[test_index]\n",
    "                y_train_fold, y_test_fold = y_old[train_index], y_old[test_index]\n",
    "                RF_co = RandomForestClassifier(max_depth = i, n_estimators = j, class_weight=balance)\n",
    "                RF_co.fit(X_train_fold, y_train_fold)\n",
    "                RF_co_prd=RF_co.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_co_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_dfOps = pd.DataFrame(lis)\n",
    "    df_rf_baOps = lis_dfOps.sort_values(by=[5], ascending=False)\n",
    "    rf_o_result_dfs.append(df_rf_baOps.head(1))\n",
    "final_Oresult_df = pd.concat(rf_o_result_dfs, ignore_index=True)\n",
    "#df_rf_pc5p = lis_df5p.sort_values(by=[5], ascending=False)\n",
    "#print(df_rf_pc5p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate F1 and medical cost ##\n",
    "\n",
    "final_Oresult_df['f1'] = 2* final_Oresult_df[4] * final_Oresult_df[6]/(final_Oresult_df[4] + final_Oresult_df[6])\n",
    "final_Oresult_df['cost'] = final_Oresult_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get feature importance ##\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "balance = {0: 1, 1: 200}\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(max_depth = 2, n_estimators = 1000, class_weight=balance)\n",
    "feature_importances_list = []\n",
    "for train_index, test_index in kf.split(X_old):\n",
    "    X_train, X_test = X_old.loc[train_index], X_old.loc[test_index]\n",
    "    y_train, y_test = y_old[train_index], y_old[test_index]\n",
    "\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    feature_importances_list.append(rf_classifier.feature_importances_)\n",
    "average_feature_importances = np.mean(feature_importances_list, axis=0)\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': average_feature_importances})\n",
    "\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = {0: 1, 1: 200}\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(max_depth = 2, n_estimators = 1000, class_weight=balance)\n",
    "feature_importances_list = []\n",
    "for train_index, test_index in kf.split(X_new):\n",
    "    X_train, X_test = X_new.loc[train_index], X_new.loc[test_index]\n",
    "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
    "\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    feature_importances_list.append(rf_classifier.feature_importances_)\n",
    "average_feature_importances = np.mean(feature_importances_list, axis=0)\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': average_feature_importances})\n",
    "\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate models for old data on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate model for old data on new data ##\n",
    "\n",
    "balance = {0: 1, 1: 200}\n",
    "X_train, X_test, y_train, y_test = X_old, X_new, y_old, y_new\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(max_depth = 2, n_estimators = 1000, class_weight=balance, random_state = 10)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "RF_prd=rf_classifier.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, RF_prd).ravel()\n",
    "ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "spe = 1.*tn/(tn+fp)\n",
    "sens = 1.*tp/(tp+fn)\n",
    "pres = tp/(tp+fp)\n",
    "npvs = tn/(tn+fn)\n",
    "cos = 565.*fn + 1.*fp\n",
    "lis=[ba,spe,sens,pres,npvs,cos]\n",
    "lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate model for old data on new data ##\n",
    "\n",
    "balance = {0: 1, 1: 300}\n",
    "X_train, X_test, y_train, y_test = X_old, X_new, y_old, y_new\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=4, class_weight=balance, random_state = 10)\n",
    "                \n",
    "# Train the model\n",
    "DT.fit(X_train, y_train)\n",
    "DT_prd=DT.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, DT_prd).ravel()\n",
    "ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "spe = 1.*tn/(tn+fp)\n",
    "sens = 1.*tp/(tp+fn)\n",
    "pres = tp/(tp+fp)\n",
    "npvs = tn/(tn+fn)\n",
    "cos = 565.*fn + 1.*fp\n",
    "lis=[ba,spe,sens,pres,npvs,cos]\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate model for old data on new data ##\n",
    "\n",
    "balance = {0: 1, 1: 300}\n",
    "X_train, X_test, y_train, y_test = X_old, X_new, y_old, y_new\n",
    "\n",
    "sv = SVC(C = 0.01, kernel = 'rbf', class_weight=balance, random_state = 10)\n",
    "                \n",
    "# Train the model\n",
    "sv.fit(X_train, y_train)\n",
    "sv_prd=sv.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, sv_prd).ravel()\n",
    "ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "spe = 1.*tn/(tn+fp)\n",
    "sens = 1.*tp/(tp+fn)\n",
    "pres = tp/(tp+fp)\n",
    "npvs = tn/(tn+fn)\n",
    "cos = 565.*fn + 1.*fp\n",
    "lis=[ba,spe,sens,pres,npvs,cos]\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate model for old data on new data ##\n",
    "\n",
    "balance = {0: 1, 1: 300}\n",
    "X_train, X_test, y_train, y_test = X_old, X_new, y_old, y_new\n",
    "\n",
    "LogReg1 = LogisticRegression(C=0.01, penalty='l1', solver='liblinear', class_weight=balance, random_state = 10)\n",
    "                \n",
    "# Train the model\n",
    "LogReg1.fit(X_train, y_train)\n",
    "LogReg1_prd=LogReg1.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, LogReg1_prd).ravel()\n",
    "ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "spe = 1.*tn/(tn+fp)\n",
    "sens = 1.*tp/(tp+fn)\n",
    "pres = tp/(tp+fp)\n",
    "npvs = tn/(tn+fn)\n",
    "cos = 565.*fn + 1.*fp\n",
    "lis=[ba,spe,sens,pres,npvs,cos]\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate model for old data on new data ##\n",
    "\n",
    "balance = {0: 1, 1: 300}\n",
    "X_train, X_test, y_train, y_test = X_old, X_new, y_old, y_new\n",
    "\n",
    "LogReg2 = LogisticRegression(C=0.01, penalty='l2', solver='liblinear', class_weight=balance, random_state = 10)\n",
    "                \n",
    "# Train the model\n",
    "LogReg2.fit(X_train, y_train)\n",
    "LogReg2_prd=LogReg2.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, LogReg2_prd).ravel()\n",
    "ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "spe = 1.*tn/(tn+fp)\n",
    "sens = 1.*tp/(tp+fn)\n",
    "pres = tp/(tp+fp)\n",
    "npvs = tn/(tn+fn)\n",
    "cos = 565.*fn + 1.*fp\n",
    "lis=[ba,spe,sens,pres,npvs,cos]\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "rf_n_result_dfs = []\n",
    "for balance in balances:\n",
    "    print('I am bal')\n",
    "    lis = []\n",
    "    for i in m_dep:\n",
    "        for j in n_est:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_n, y_new):\n",
    "                X_train_fold, X_test_fold = scaled_n[train_index], scaled_n[test_index]\n",
    "                y_train_fold, y_test_fold = y_new[train_index], y_new[test_index]\n",
    "                RF_cn = RandomForestClassifier(max_depth = i, n_estimators = j, class_weight=balance)\n",
    "                RF_cn.fit(X_train_fold, y_train_fold)\n",
    "                RF_cn_prd=RF_cn.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_cn_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_dfNps = pd.DataFrame(lis)\n",
    "    df_rf_baNps = lis_dfNps.sort_values(by=[5], ascending=False)\n",
    "    rf_n_result_dfs.append(df_rf_baNps.head(1))\n",
    "final_Nresult_df = pd.concat(rf_n_result_dfs, ignore_index=True)\n",
    "#df_rf_pc5p = lis_df5p.sort_values(by=[5], ascending=False)\n",
    "#print(df_rf_pc5p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Nresult_df = pd.concat(rf_n_result_dfs, ignore_index=True)\n",
    "final_Nresult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Nresult_df['f1'] = 2* final_Nresult_df[4] * final_Nresult_df[6]/(final_Nresult_df[4] + final_Nresult_df[6])\n",
    "final_Nresult_df['cost'] = final_Nresult_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "sv_o_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in c:\n",
    "        for j in ker:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_o, y_old):\n",
    "                X_train_fold, X_test_fold = scaled_o[train_index], scaled_o[test_index]\n",
    "                y_train_fold, y_test_fold = y_old[train_index], y_old[test_index]\n",
    "                sv = SVC(C = i, kernel = j, class_weight=balance)\n",
    "                sv.fit(X_train_fold, y_train_fold)\n",
    "                sv_prd=sv.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_svo = pd.DataFrame(lis)\n",
    "    df_svo = lis_svo.sort_values(by=[5], ascending=False)\n",
    "    sv_o_result_dfs.append(df_svo.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svo_result_df = pd.concat(sv_o_result_dfs, ignore_index=True)\n",
    "final_svo_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svo_result_df['f1'] = 2* final_svo_result_df[4] * final_svo_result_df[6]/(final_svo_result_df[4] + final_svo_result_df[6])\n",
    "final_svo_result_df['cost'] = final_svo_result_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "sv_n_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in c:\n",
    "        for j in ker:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_n, y_new):\n",
    "                X_train_fold, X_test_fold = scaled_n[train_index], scaled_n[test_index]\n",
    "                y_train_fold, y_test_fold = y_new[train_index], y_new[test_index]\n",
    "                sv = SVC(C = i, kernel = j, class_weight=balance)\n",
    "                sv.fit(X_train_fold, y_train_fold)\n",
    "                sv_prd=sv.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_svn = pd.DataFrame(lis)\n",
    "    df_svn = lis_svn.sort_values(by=[5], ascending=False)\n",
    "    sv_n_result_dfs.append(df_svn.head(1))\n",
    "final_svn_result_df = pd.concat(sv_n_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svn_result_df['f1'] = 2* final_svn_result_df[4] * final_svn_result_df[6]/(final_svn_result_df[4] + final_svn_result_df[6])\n",
    "final_svn_result_df['cost'] = final_svn_result_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "dt_o_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in m_dep:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled_o, y_old):\n",
    "                X_train_fold, X_test_fold = scaled_o[train_index], scaled_o[test_index]\n",
    "                y_train_fold, y_test_fold = y_old[train_index], y_old[test_index]\n",
    "                DT = DecisionTreeClassifier(max_depth=i, class_weight=balance)\n",
    "                DT.fit(X_train_fold, y_train_fold)\n",
    "                DT_prd=DT.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([balance,i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_dto = pd.DataFrame(lis)\n",
    "    df_dto = lis_dto.sort_values(by=[4], ascending=False)\n",
    "    dt_o_result_dfs.append(df_dto.head(1))\n",
    "final_dto_result_df = pd.concat(dt_o_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dto_result_df['f1'] = 2* final_dto_result_df[5] * final_dto_result_df[3]/(final_dto_result_df[5] + final_dto_result_df[3])\n",
    "final_dto_result_df['cost'] = final_dto_result_df[7] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "dt_n_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in m_dep:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled_n, y_new):\n",
    "                X_train_fold, X_test_fold = scaled_n[train_index], scaled_n[test_index]\n",
    "                y_train_fold, y_test_fold = y_new[train_index], y_new[test_index]\n",
    "                DT = DecisionTreeClassifier(max_depth=i, class_weight=balance)\n",
    "                DT.fit(X_train_fold, y_train_fold)\n",
    "                DT_prd=DT.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([balance,i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_dtn = pd.DataFrame(lis)\n",
    "    df_dtn = lis_dtn.sort_values(by=[4], ascending=False)\n",
    "    dt_n_result_dfs.append(df_dtn.head(1))\n",
    "final_dtn_result_df = pd.concat(dt_n_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dtn_result_df['f1'] = 2* final_dtn_result_df[5] * final_dtn_result_df[3]/(final_dtn_result_df[5] + final_dtn_result_df[3])\n",
    "final_dtn_result_df['cost'] = final_dtn_result_df[7] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "l1_o_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in c:\n",
    "        for j in sol:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_o, y_old):\n",
    "                X_train_fold, X_test_fold = scaled_o[train_index], scaled_o[test_index]\n",
    "                y_train_fold, y_test_fold = y_old[train_index], y_old[test_index]\n",
    "                LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j, class_weight=balance)\n",
    "                LogReg1.fit(X_train_fold, y_train_fold)\n",
    "                LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_lr1o = pd.DataFrame(lis)\n",
    "    df_lr1o = lis_lr1o.sort_values(by=[5], ascending=False)\n",
    "    l1_o_result_dfs.append(df_lr1o.head(1))\n",
    "final_lr1o_result_df = pd.concat(l1_o_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr1o_result_df['f1'] = 2* final_lr1o_result_df[6] * final_lr1o_result_df[4]/(final_lr1o_result_df[6] + final_lr1o_result_df[4])\n",
    "final_lr1o_result_df['cost'] = final_lr1o_result_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "l1_n_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in c:\n",
    "        for j in sol:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_n, y_new):\n",
    "                X_train_fold, X_test_fold = scaled_n[train_index], scaled_n[test_index]\n",
    "                y_train_fold, y_test_fold = y_new[train_index], y_new[test_index]\n",
    "                LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j, class_weight=balance)\n",
    "                LogReg1.fit(X_train_fold, y_train_fold)\n",
    "                LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_lr1n = pd.DataFrame(lis)\n",
    "    df_lr1n = lis_lr1n.sort_values(by=[5], ascending=False)\n",
    "    l1_n_result_dfs.append(df_lr1n.head(1))\n",
    "final_lr1n_result_df = pd.concat(l1_n_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr1n_result_df['f1'] = 2* final_lr1n_result_df[6] * final_lr1n_result_df[4]/(final_lr1n_result_df[6] + final_lr1n_result_df[4])\n",
    "final_lr1n_result_df['cost'] = final_lr1n_result_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "l2_o_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in c:\n",
    "        for j in sol:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_o, y_old):\n",
    "                X_train_fold, X_test_fold = scaled_o[train_index], scaled_o[test_index]\n",
    "                y_train_fold, y_test_fold = y_old[train_index], y_old[test_index]\n",
    "                LogReg2 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "                LogReg2.fit(X_train_fold, y_train_fold)\n",
    "                LogReg2_prd=LogReg2.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg2_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_lr2o = pd.DataFrame(lis)\n",
    "    df_lr2o = lis_lr2o.sort_values(by=[5], ascending=False)\n",
    "    l2_o_result_dfs.append(df_lr2o.head(1))\n",
    "final_lr2o_result_df = pd.concat(l2_o_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr2o_result_df['f1'] = 2* final_lr2o_result_df[6] * final_lr2o_result_df[4]/(final_lr2o_result_df[6] + final_lr2o_result_df[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr2o_result_df['cost'] = final_lr2o_result_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balances = [{0: 1, 1: 1}, {0: 1, 1: 200}, {0: 1, 1: 300}, {0: 1, 1: 500}, {0: 1, 1: 1000}]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "l2_n_result_dfs = []\n",
    "for balance in balances:\n",
    "    lis = []\n",
    "    for i in c:\n",
    "        for j in sol:\n",
    "            lst_bala_accu_stratified = []\n",
    "            lst_spe_stratified = []\n",
    "            lst_sens_stratified = []\n",
    "            lst_exp_cost = []\n",
    "            lst_pre = []\n",
    "            lst_npv = []\n",
    "            for train_index, test_index in skf.split(scaled_n, y_new):\n",
    "                X_train_fold, X_test_fold = scaled_n[train_index], scaled_n[test_index]\n",
    "                y_train_fold, y_test_fold = y_new[train_index], y_new[test_index]\n",
    "                LogReg2 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "                LogReg2.fit(X_train_fold, y_train_fold)\n",
    "                LogReg2_prd=LogReg2.predict(X_test_fold)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg2_prd).ravel()\n",
    "                ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "                spe = 1.*tn/(tn+fp)\n",
    "                sens = 1.*tp/(tp+fn)\n",
    "                pres = tp/(tp+fp)\n",
    "                npvs = tn/(tn+fn)\n",
    "                cos = 565.*fn + 1.*fp\n",
    "                lst_bala_accu_stratified.append(ba)\n",
    "                lst_spe_stratified.append(spe)\n",
    "                lst_sens_stratified.append(sens)\n",
    "                lst_exp_cost.append(cos)\n",
    "                lst_pre.append(pres)\n",
    "                lst_npv.append(npvs)\n",
    "            #print(np.mean(lst_bala_accu_stratified))\n",
    "            lis.append([balance,i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                        np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "    lis_lr2n = pd.DataFrame(lis)\n",
    "    df_lr2n = lis_lr2n.sort_values(by=[5], ascending=False)\n",
    "    l2_n_result_dfs.append(df_lr2n.head(1))\n",
    "final_lr2n_result_df = pd.concat(l2_n_result_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr2n_result_df['f1'] = 2* final_lr2n_result_df[6] * final_lr2n_result_df[4]/(final_lr2n_result_df[6] + final_lr2n_result_df[4])\n",
    "final_lr2n_result_df['cost'] = final_lr2n_result_df[8] * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in m_dep:\n",
    "    for j in n_est:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            RF_c5 = RandomForestClassifier(max_depth = i, n_estimators = j, class_weight=balance)\n",
    "            RF_c5.fit(X_train_fold, y_train_fold)\n",
    "            RF_c5_prd=RF_c5.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_c5_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_df5ps = pd.DataFrame(lis)\n",
    "df_rf_ba5ps = lis_df5ps.sort_values(by=[4], ascending=False)\n",
    "#df_rf_pc5p = lis_df5p.sort_values(by=[5], ascending=False)\n",
    "print(df_rf_ba5ps.head(1))\n",
    "#print(df_rf_pc5p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:200}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in m_dep:\n",
    "    for j in n_est:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            RF_c5 = RandomForestClassifier(max_depth = i, n_estimators = j, class_weight=balance)\n",
    "            RF_c5.fit(X_train_fold, y_train_fold)\n",
    "            RF_c5_prd=RF_c5.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_c5_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_df2ps = pd.DataFrame(lis)\n",
    "df_rf_ba2ps = lis_df2ps.sort_values(by=[4], ascending=False)\n",
    "#df_rf_pc2p = lis_df2p.sort_values(by=[5], ascending=False)\n",
    "print(df_rf_ba2ps.head(1))\n",
    "#print(df_rf_pc2p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in m_dep:\n",
    "    for j in n_est:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            RF_c5 = RandomForestClassifier(max_depth = i, n_estimators = j, class_weight=balance)\n",
    "            RF_c5.fit(X_train_fold, y_train_fold)\n",
    "            RF_c5_prd=RF_c5.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_c5_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_df3ps = pd.DataFrame(lis)\n",
    "df_rf_ba3ps = lis_df3ps.sort_values(by=[4], ascending=False)\n",
    "#df_rf_pc2p = lis_df2p.sort_values(by=[5], ascending=False)\n",
    "print(df_rf_ba3ps.head(1))\n",
    "#print(df_rf_pc2p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:1000}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in m_dep:\n",
    "    for j in n_est:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            RF_c5 = RandomForestClassifier(max_depth = i, n_estimators = j, class_weight=balance)\n",
    "            RF_c5.fit(X_train_fold, y_train_fold)\n",
    "            RF_c5_prd=RF_c5.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_c5_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_df10ps = pd.DataFrame(lis)\n",
    "df_rf_ba10ps = lis_df10ps.sort_values(by=[4], ascending=False)\n",
    "#df_rf_pc2p = lis_df2p.sort_values(by=[5], ascending=False)\n",
    "print(df_rf_ba10ps.head(1))\n",
    "#print(df_rf_pc2p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "#balance = {0:1,1:200}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "n_est = [5, 10, 100, 500, 1000]\n",
    "#m_fea = ['sqrt','log2']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in m_dep:\n",
    "    for j in n_est:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            RF_c5 = RandomForestClassifier(max_depth = i, n_estimators = j)\n",
    "            RF_c5.fit(X_train_fold, y_train_fold)\n",
    "            RF_c5_prd=RF_c5.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, RF_c5_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = 1.*tp/(tp+fp)\n",
    "            npvs = 1.*tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_df0ps = pd.DataFrame(lis)\n",
    "df_rf_ba0ps = lis_df0ps.sort_values(by=[4], ascending=False)\n",
    "#df_rf_pc2p = lis_df2p.sort_values(by=[5], ascending=False)\n",
    "print(df_rf_ba0ps.head(1))\n",
    "#print(df_rf_pc2p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr3ps = pd.DataFrame(lis)\n",
    "df_lr_ba3ps = lis_lr3ps.sort_values(by=[4], ascending=False)\n",
    "#df_lr_pc3p = lis_lr3p.sort_values(by=[5], ascending=False)\n",
    "print(df_lr_ba3ps.head(1))\n",
    "#print(df_lr_pc3p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:200}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr2ps = pd.DataFrame(lis)\n",
    "df_lr_ba2ps = lis_lr2ps.sort_values(by=[4], ascending=False)\n",
    "#df_lr_pc3p = lis_lr3p.sort_values(by=[5], ascending=False)\n",
    "print(df_lr_ba2ps.head(1))\n",
    "#print(df_lr_pc3p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr5ps = pd.DataFrame(lis)\n",
    "df_lr_ba5ps = lis_lr5ps.sort_values(by=[4], ascending=False)\n",
    "#df_lr_pc3p = lis_lr3p.sort_values(by=[5], ascending=False)\n",
    "print(df_lr_ba5ps.head(1))\n",
    "#print(df_lr_pc3p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:1000}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr10ps = pd.DataFrame(lis)\n",
    "df_lr_ba10ps = lis_lr10ps.sort_values(by=[4], ascending=False)\n",
    "#df_lr_pc3p = lis_lr3p.sort_values(by=[5], ascending=False)\n",
    "print(df_lr_ba10ps.head(1))\n",
    "#print(df_lr_pc3p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr0ps = pd.DataFrame(lis)\n",
    "df_lr_ba0ps = lis_lr0ps.sort_values(by=[4], ascending=False)\n",
    "#df_lr_pc3p = lis_lr3p.sort_values(by=[5], ascending=False)\n",
    "print(df_lr_ba0ps.head(1))\n",
    "#print(df_lr_pc3p.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:1000}\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in ker:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            sv = SVC(C = i, kernel = j, class_weight=balance)\n",
    "            sv.fit(X_train_fold, y_train_fold)\n",
    "            sv_prd=sv.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_sv10 = pd.DataFrame(lis)\n",
    "df_sv10 = lis_sv10.sort_values(by=[4], ascending=False)\n",
    "print(df_sv10.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in ker:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            sv = SVC(C = i, kernel = j, class_weight=balance)\n",
    "            sv.fit(X_train_fold, y_train_fold)\n",
    "            sv_prd=sv.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_sv5 = pd.DataFrame(lis)\n",
    "df_sv5 = lis_sv5.sort_values(by=[4], ascending=False)\n",
    "print(df_sv5.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in ker:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            sv = SVC(C = i, kernel = j, class_weight=balance)\n",
    "            sv.fit(X_train_fold, y_train_fold)\n",
    "            sv_prd=sv.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_sv3 = pd.DataFrame(lis)\n",
    "df_sv3 = lis_sv3.sort_values(by=[4], ascending=False)\n",
    "print(df_sv3.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:200}\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in ker:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            sv = SVC(C = i, kernel = j, class_weight=balance)\n",
    "            sv.fit(X_train_fold, y_train_fold)\n",
    "            sv_prd=sv.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_sv2 = pd.DataFrame(lis)\n",
    "df_sv2 = lis_sv2.sort_values(by=[4], ascending=False)\n",
    "print(df_sv2.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "#balance = {0:1,1:1000}\n",
    "c = [50, 10, 1.0, 0.1, 0.01]\n",
    "ker = ['poly', 'rbf', 'sigmoid']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in ker:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            sv = SVC(C = i, kernel = j)\n",
    "            sv.fit(X_train_fold, y_train_fold)\n",
    "            sv_prd=sv.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, sv_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_sv0 = pd.DataFrame(lis)\n",
    "df_sv0 = lis_sv0.sort_values(by=[4], ascending=False)\n",
    "print(df_sv0.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:1000}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "for i in m_dep:\n",
    "    lst_bala_accu_stratified = []\n",
    "    lst_spe_stratified = []\n",
    "    lst_sens_stratified = []\n",
    "    lst_exp_cost = []\n",
    "    lst_pre = []\n",
    "    lst_npv = []\n",
    "    for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            DT = DecisionTreeClassifier(max_depth=i, class_weight=balance)\n",
    "            DT.fit(X_train_fold, y_train_fold)\n",
    "            DT_prd=DT.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "    #print(np.mean(lst_bala_accu_stratified))\n",
    "    lis.append([i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_dt10 = pd.DataFrame(lis)\n",
    "df_dt10 = lis_dt10.sort_values(by=[3], ascending=False)\n",
    "print(df_dt10.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "for i in m_dep:\n",
    "    lst_bala_accu_stratified = []\n",
    "    lst_spe_stratified = []\n",
    "    lst_sens_stratified = []\n",
    "    lst_exp_cost = []\n",
    "    lst_pre = []\n",
    "    lst_npv = []\n",
    "    for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            DT = DecisionTreeClassifier(max_depth=i, class_weight=balance)\n",
    "            DT.fit(X_train_fold, y_train_fold)\n",
    "            DT_prd=DT.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "    #print(np.mean(lst_bala_accu_stratified))\n",
    "    lis.append([i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_dt5 = pd.DataFrame(lis)\n",
    "df_dt5 = lis_dt5.sort_values(by=[3], ascending=False)\n",
    "print(df_dt5.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:200}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "for i in m_dep:\n",
    "    lst_bala_accu_stratified = []\n",
    "    lst_spe_stratified = []\n",
    "    lst_sens_stratified = []\n",
    "    lst_exp_cost = []\n",
    "    lst_pre = []\n",
    "    lst_npv = []\n",
    "    for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            DT = DecisionTreeClassifier(max_depth=i, class_weight=balance)\n",
    "            DT.fit(X_train_fold, y_train_fold)\n",
    "            DT_prd=DT.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "    #print(np.mean(lst_bala_accu_stratified))\n",
    "    lis.append([i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_dt2 = pd.DataFrame(lis)\n",
    "df_dt2 = lis_dt2.sort_values(by=[3], ascending=False)\n",
    "print(df_dt2.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "for i in m_dep:\n",
    "    lst_bala_accu_stratified = []\n",
    "    lst_spe_stratified = []\n",
    "    lst_sens_stratified = []\n",
    "    lst_exp_cost = []\n",
    "    lst_pre = []\n",
    "    lst_npv = []\n",
    "    for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            DT = DecisionTreeClassifier(max_depth=i, class_weight=balance)\n",
    "            DT.fit(X_train_fold, y_train_fold)\n",
    "            DT_prd=DT.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "    #print(np.mean(lst_bala_accu_stratified))\n",
    "    lis.append([i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_dt3 = pd.DataFrame(lis)\n",
    "df_dt3 = lis_dt3.sort_values(by=[3], ascending=False)\n",
    "print(df_dt3.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "#balance = {0:1,1:300}\n",
    "m_dep = [2, 4, 6, 8, 10, 50, 100]\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "for i in m_dep:\n",
    "    lst_bala_accu_stratified = []\n",
    "    lst_spe_stratified = []\n",
    "    lst_sens_stratified = []\n",
    "    lst_exp_cost = []\n",
    "    lst_pre = []\n",
    "    lst_npv = []\n",
    "    for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            DT = DecisionTreeClassifier(max_depth=i)\n",
    "            DT.fit(X_train_fold, y_train_fold)\n",
    "            DT_prd=DT.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, DT_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "    #print(np.mean(lst_bala_accu_stratified))\n",
    "    lis.append([i,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_dt0 = pd.DataFrame(lis)\n",
    "df_dt0 = lis_dt0.sort_values(by=[3], ascending=False)\n",
    "print(df_dt0.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:200}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr2 = pd.DataFrame(lis)\n",
    "df_lr2 = lis_lr2.sort_values(by=[4], ascending=False)\n",
    "print(df_lr2.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr31 = pd.DataFrame(lis)\n",
    "df_lr31 = lis_lr31.sort_values(by=[4], ascending=False)\n",
    "print(df_lr31.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr5 = pd.DataFrame(lis)\n",
    "df_lr5 = lis_lr5.sort_values(by=[4], ascending=False)\n",
    "print(df_lr5.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:1000}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr10 = pd.DataFrame(lis)\n",
    "df_lr10 = lis_lr10.sort_values(by=[4], ascending=False)\n",
    "print(df_lr10.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "#balance = {0:1,1:200}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['liblinear','saga']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        lst_exp_cost = []\n",
    "        lst_pre = []\n",
    "        lst_npv = []\n",
    "        for train_index, test_index in skf.split(scaled, y):\n",
    "            X_train_fold, X_test_fold = scaled[train_index], scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l1', solver=j)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            pres = tp/(tp+fp)\n",
    "            npvs = tn/(tn+fn)\n",
    "            cos = 565.*fn + 1.*fp\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "            lst_exp_cost.append(cos)\n",
    "            lst_pre.append(pres)\n",
    "            lst_npv.append(npvs)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified),\n",
    "                    np.mean(lst_pre),np.mean(lst_npv),np.mean(lst_exp_cost)])\n",
    "lis_lr0 = pd.DataFrame(lis)\n",
    "df_lr0 = lis_lr0.sort_values(by=[4], ascending=False)\n",
    "print(df_lr0.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:200}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg.fit(X_train_fold, y_train_fold)\n",
    "            LogReg_prd=LogReg.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified)])\n",
    "lis_lr = pd.DataFrame(lis)\n",
    "df_lr = lis_lr.sort_values(by=[4], ascending=False)\n",
    "print(df_lr.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "lst_bala_accu_stratified = []\n",
    "lst_spe_stratified = []\n",
    "lst_sens_stratified = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    LogReg = LogisticRegression(C=0.1, penalty='l2', solver='liblinear', class_weight=balance)\n",
    "    LogReg.fit(X_train_fold, y_train_fold)\n",
    "    LogReg_prd=LogReg.predict(X_test_fold)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg_prd).ravel()\n",
    "    ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "    spe = 1.*tn/(tn+fp)\n",
    "    sens = 1.*tp/(tp+fn)\n",
    "    lst_bala_accu_stratified.append(ba)\n",
    "    lst_spe_stratified.append(spe)\n",
    "    lst_sens_stratified.append(sens)\n",
    "print(lst_bala_accu_stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        for train_index, test_index in skf.split(X_nobp, y):\n",
    "            X_train_fold, X_test_fold = X_nobp.loc[train_index], X_nobp.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified)])\n",
    "lis_lr = pd.DataFrame(lis)\n",
    "df_lr = lis_lr.sort_values(by=[4], ascending=False)\n",
    "print(df_lr.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified)])\n",
    "lis_lr = pd.DataFrame(lis)\n",
    "df_lr = lis_lr.sort_values(by=[4], ascending=False)\n",
    "print(df_lr.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified)])\n",
    "lis_lr = pd.DataFrame(lis)\n",
    "df_lr = lis_lr.sort_values(by=[4], ascending=False)\n",
    "print(df_lr.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "balance = {0:1,1:1000}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j, class_weight=balance)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified)])\n",
    "lis_lr = pd.DataFrame(lis)\n",
    "df_lr = lis_lr.sort_values(by=[4], ascending=False)\n",
    "print(df_lr.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StratifiedKFold cross validation ##\n",
    "\n",
    "#balance = {0:1,1:1000}\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "sol = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "lis = []\n",
    "#StratifiedKFold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "#main loop for tuning\n",
    "for i in c:\n",
    "    for j in sol:\n",
    "        lst_bala_accu_stratified = []\n",
    "        lst_spe_stratified = []\n",
    "        lst_sens_stratified = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "            LogReg1 = LogisticRegression(C=i, penalty='l2', solver=j)\n",
    "            LogReg1.fit(X_train_fold, y_train_fold)\n",
    "            LogReg1_prd=LogReg1.predict(X_test_fold)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test_fold, LogReg1_prd).ravel()\n",
    "            ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "            spe = 1.*tn/(tn+fp)\n",
    "            sens = 1.*tp/(tp+fn)\n",
    "            lst_bala_accu_stratified.append(ba)\n",
    "            lst_spe_stratified.append(spe)\n",
    "            lst_sens_stratified.append(sens)\n",
    "        #print(np.mean(lst_bala_accu_stratified))\n",
    "        lis.append([i,j,np.mean(lst_spe_stratified),np.mean(lst_sens_stratified),np.mean(lst_bala_accu_stratified)])\n",
    "lis_lr = pd.DataFrame(lis)\n",
    "df_lr = lis_lr.sort_values(by=[4], ascending=False)\n",
    "print(df_lr.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC curves ##\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "balance = {0:1,1:500}\n",
    "classifier = RandomForestClassifier(max_depth = 6, n_estimators = 1000, class_weight=balance)\n",
    "classifier.fit(X, y)\n",
    "probs = classifier.predict_proba(X)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "classifier.fit(X_nobp, y)\n",
    "probs_n = classifier.predict_proba(X_nobp)\n",
    "preds_n = probs_n[:,1]\n",
    "fpr_n, tpr_n, threshold = metrics.roc_curve(y, preds_n)\n",
    "roc_auc_n = metrics.auc(fpr_n, tpr_n)\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('ROC curve with and without BP features\\n(Positive label \"Readmission\")')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC with BP = %0.2f' % roc_auc)\n",
    "plt.plot(fpr_n, tpr_n, 'orange', label = 'AUC without BP = %0.2f' % roc_auc_n)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "#plt.show()\n",
    "plt.savefig('ROC_compare.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More ROC curves ##\n",
    "\n",
    "balance = {0:1,1:500}\n",
    "#cv = StratifiedKFold(n_splits=5)\n",
    "classifier = RandomForestClassifier(max_depth = 6, n_estimators = 1000, class_weight=balance, random_state=10)\n",
    "#clf = RandomForestClassifier(random_state=random_state)\n",
    "cv = StratifiedKFold(n_splits=10,shuffle=False)\n",
    "# plot arrows\n",
    "fig1 = plt.figure(figsize=[6,6])\n",
    "ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "#ax1.add_patch(\n",
    "#    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "#    )\n",
    "#ax1.add_patch(\n",
    "#    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "#    )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "#i = 1\n",
    "for train,test in cv.split(X,y):\n",
    "    prediction = classifier.fit(X.iloc[train],y.iloc[train]).predict_proba(X.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(y[test], prediction[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    #i= i+1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=1)\n",
    "\n",
    "tprs_n = []\n",
    "aucs_n = []\n",
    "mean_fpr_n = np.linspace(0,1,100)\n",
    "#i = 1\n",
    "for train,test in cv.split(X_nobp,y):\n",
    "    prediction_n = classifier.fit(X_nobp.iloc[train],y.iloc[train]).predict_proba(X_nobp.iloc[test])\n",
    "    fpr, tpr, t = roc_curve(y[test], prediction_n[:, 1])\n",
    "    tprs_n.append(interp(mean_fpr_n, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs_n.append(roc_auc)\n",
    "    #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    #i= i+1\n",
    "\n",
    "#plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "mean_tpr_n = np.mean(tprs_n, axis=0)\n",
    "mean_auc_n = auc(mean_fpr_n, mean_tpr_n)\n",
    "std_auc_n = np.std(aucs_n)\n",
    "plt.plot(mean_fpr_n, mean_tpr_n, color='orange',\n",
    "         label=r'Mean ROC WITHOUT BP (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_n, std_auc_n),lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve with and without BP features')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "#plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "plt.savefig('final_Mean_ROC.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More ROC curves ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "classifier = LogisticRegression(C=0.1, penalty='l2', solver='liblinear', class_weight=balance)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.loc[train], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.loc[test],\n",
    "        y[test],\n",
    "        name=f\"ROC fold {fold}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with BP features\\n(Positive label 'Readmission')\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "plt.savefig('Mean_ROC_bp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More ROC curves ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "balance = {0:1,1:300}\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "classifier = LogisticRegression(C=0.1, penalty='l2', solver='liblinear', class_weight=balance)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for fold, (train, test) in enumerate(cv.split(X_nobp, y)):\n",
    "    classifier.fit(X_nobp.loc[train], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X_nobp.loc[test],\n",
    "        y[test],\n",
    "        name=f\"ROC fold {fold}\",\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve without BP features\\n(Positive label 'Readmission')\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "plt.savefig('Mean_ROC_wo_bp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Random Forest\n",
    "y_predRF_c5 = RF_c5.predict_proba(X_test).T[1]\n",
    "fprRf5, tprRf5, threshRf5 = roc_curve(y_test, y_predRF_c5)\n",
    "roc_auc_rf5= roc_auc_score(y_test, y_predRF_c5)\n",
    "\n",
    "y_predRF_c2 = RF_c2.predict_proba(X_test).T[1]\n",
    "fprRf2, tprRf2, threshRf2 = roc_curve(y_test, y_predRF_c2)\n",
    "roc_auc_rf2= roc_auc_score(y_test, y_predRF_c2)\n",
    "\n",
    "y_predRF_c3 = RF_c3.predict_proba(X_test).T[1]\n",
    "fprRf3, tprRf3, threshRf3 = roc_curve(y_test, y_predRF_c3)\n",
    "roc_auc_rf3= roc_auc_score(y_test, y_predRF_c3)\n",
    "\n",
    "y_predRF_c10 = RF_c10.predict_proba(X_test).T[1]\n",
    "fprRf10, tprRf10, threshRf10 = roc_curve(y_test, y_predRF_c10)\n",
    "roc_auc_rf10= roc_auc_score(y_test, y_predRF_c10)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "plt.plot(fprRf2, tprRf2, label='cost ratio 200 (AUC = %0.3f)' % roc_auc_rf2) \n",
    "plt.plot(fprRf3, tprRf3, label='cost ratio 300 (AUC = %0.3f)' % roc_auc_rf3) \n",
    "plt.plot(fprRf5, tprRf5, label='cost ratio 500 (AUC = %0.3f)' % roc_auc_rf5) \n",
    "plt.plot(fprRf10, tprRf10, label='cost ratio 1000 (AUC = %0.3f)' % roc_auc_rf10) \n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC Comparison of Different Models with BP features', fontsize = 15)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right');\n",
    "plt.savefig('ROC_wo_bp.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion matrix ##\n",
    "\n",
    "def display_summary(true,pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(true,pred).ravel()\n",
    "    print('confusion matrix')\n",
    "    print(np.array([[tp,fp],[fn,tn]]))\n",
    "    print('sensitivity is %f',1.*tp/(tp+fn))\n",
    "    print('specificity is %f',1.*tn/(tn+fp))\n",
    "    print('accuracy is %f',1.*(tp+tn)/(tp+tn+fp+fn))\n",
    "    print('balanced accuracy is %',1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Leave one out prediction performance ##\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "# Define the balance dictionary\n",
    "balance = {0: 1, 1: 500}\n",
    "\n",
    "# Initialize RandomForestClassifier parameters\n",
    "max_depth = 6\n",
    "n_estimators = 1000\n",
    "random_state = 10\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "RF_c5 = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=random_state, class_weight=balance)\n",
    "loo = LeaveOneOut()\n",
    "results = np.empty(len(X))\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(loo.split(X)):\n",
    "    print(i)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    RF_c5.fit(X_train, y_train)\n",
    "\n",
    "    y_probabilities = RF_c5.predict_proba(X_test)\n",
    "    results[i] = y_probabilities[:, 1][0]  # Access probabilities for class 1 (positive class) in each iteration\n",
    "    #print(results[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some key metrics measured on different prediction threshold ##\n",
    "num_samples = len(X)\n",
    "\n",
    "# Initialize variables to store results\n",
    "custom_threshold = [round(i, 2) for i in range(5, 90, 5)]\n",
    "custom_threshold = [x / 100 for x in custom_threshold]\n",
    "\n",
    "lst_bala_accu = []\n",
    "lst_preci = []\n",
    "lst_exp_cost = []\n",
    "        \n",
    "# Compute confusion matrix for each threshold\n",
    "for i in custom_threshold:\n",
    "    y_custom_predictions = (results > i).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_custom_predictions).ravel()\n",
    "    ba = 1./2*(1.*tp/(tp+fn)+1.*tn/(tn+fp))\n",
    "    preci = tp/(tp + fp)\n",
    "    cos = (565.*fn + 1.*fp)*36\n",
    "    lst_bala_accu.append(ba)\n",
    "    lst_preci.append(preci)\n",
    "    lst_exp_cost.append(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the relationship between custom threshold and expected cost\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(custom_threshold, lst_exp_cost)\n",
    "plt.title('Relationship between Predictive Threshold and Expected Medical Costs')\n",
    "plt.xlabel('Predictive Threshold')\n",
    "plt.ylabel('Expected Medical Costs')\n",
    "#plt.xticks(custom_threshold)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('predictive_threshold_cost.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between custom threshold and accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(custom_threshold, lst_bala_accu)\n",
    "plt.title('Relationship between Predictive Threshold and Balanced Accuracy')\n",
    "plt.xlabel('Predictive Threshold')\n",
    "plt.ylabel('Balanced Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('predictive_threshold_balanced_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/Troy-T/Downloads/model.joblib']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dump the best model for calculator ##\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(RF_c5, '/Users/Troy-T/Downloads/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
